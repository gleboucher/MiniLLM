{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d61be66f-1d53-43ee-97a6-48b43661d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f95d47d5-7508-4892-94c1-da27a7a97b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = nn.Embedding(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "938b8678-7988-4fed-a807-a101aa51c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0845a3df-a4a2-495d-8773-664997fa41cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32 \n",
    "block_size = 8 \n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"mps\")\n",
    "vocab_size = tokenizer.vocab_size\n",
    "n_embed = 512\n",
    "head_size = 64\n",
    "n_head = 8\n",
    "block_iter = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3637f5a-1812-4660-a4ef-d8e4d885ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Let's see how you can tokenize this sentence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01f7ea1a-fdd6-4af6-be35-ad572cbfb066",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0dcaa48-0968-40de-a273-6d702c46f941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (338025 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(tokenizer(text).input_ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef3d8709-85cd-4482-a6ed-6ca9e0727d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([338025])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307577fe-ddc1-4e57-aa21-a054b749a84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750d7ce-fe48-42b9-850a-2be89f8c878d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db42b2e4-9b88-4e46-97fd-9d30c255cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n + 2]\n",
    "test_data = data[n + 2:]\n",
    "\n",
    "\n",
    "# x shape: Batch_size, Block_size, n_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac7f81bf-e61f-4c3b-a70e-b2ad61f5cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, n_embed, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size)\n",
    "        self.value = nn.Linear(n_embed, head_size)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size )))\n",
    "        self.n_embed = n_embed\n",
    "        self.head_size = head_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        k = self.key(x) # B, T, head_size\n",
    "        q = self.query(x) # B, T, head_size\n",
    "        v = self.value(x) # B, T, head_size\n",
    "        sa = (q @ k.transpose(-2, -1)) * self.head_size ** (-0.5) \n",
    "        sa = sa.masked_fill(self.tril==0, float(\"-inf\"))\n",
    "        x = F.softmax(sa, dim=-1) @ v\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bf1f1d4-f8d6-4c06-ba85-be04bd018d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, n_embed, head_size, n_head):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.n_embed = n_embed\n",
    "        self.heads = [Head(n_embed, head_size) for _ in range (n_head)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, h = x.shape\n",
    "        output = torch.empty((b, t, 0))\n",
    "        for head in self.heads:\n",
    "            output = torch.cat((output, head(x)), -1)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89d3ba03-7567-4462-96e8-19f83b7be9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.ffn = nn.Sequential(nn.Linear(n_embed, n_embed  * 4), nn.ReLU(), nn.Linear(n_embed * 4, n_embed))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ffn(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "233f3cb3-992a-4c83-bb22-cf00d0c001e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, head_size, n_head):\n",
    "        super().__init__()\n",
    "        self.mh = MultiHead(n_embed, head_size, n_head)\n",
    "        self.ln = nn.LayerNorm(n_embed)\n",
    "        self.ffn = FFN(n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.mh(self.ln(x))\n",
    "        x = x + self.ffn(self.ln(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a1d7619-60f2-4107-8ec3-33ca78e9f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniLLM(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embed, head_size, n_head, block_iter):\n",
    "        super().__init__()\n",
    "        self.embedding_token = nn.Embedding(vocab_size, n_embed)\n",
    "        self.embedding_pos = nn.Embedding(vocab_size, n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed, head_size, n_head) for _ in range(block_iter)])\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size, bias=False)\n",
    "        self.embedding_token.weight = self.lm_head.weight\n",
    "        self.block_iter = block_iter\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        b, t = x.shape # B, T\n",
    "        embed = self.embedding_token(x) #B, T, C\n",
    "        pos = self.embedding_pos(torch.arange(t)) #C\n",
    "        x = embed + pos #B, T, C\n",
    "        x = self.blocks(x) #B, T, C\n",
    "        if target is not None:\n",
    "            logits = self.lm_head(x) #B, T, 1\n",
    "            logits = logits.view(b*t, -1)\n",
    "            target = target.view(b*t)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "        else :\n",
    "            logits = self.lm_head(x)[:, [-1], :]#B, 1\n",
    "            loss = None\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "    def generate(self, x, num_new_token=100, context_limit=8): \n",
    "        y = x\n",
    "        for _ in range(num_new_token):\n",
    "            logits, _ = self(x)\n",
    "            logit = torch.argmax(logits, dim=-1)\n",
    "            y = torch.cat((y, logit), 1)\n",
    "            if x.shape[-1] < context_limit: \n",
    "                x = torch.cat((x, logit), 1)\n",
    "            else: \n",
    "                x = torch.cat((x[:, 1:], logit), 1)\n",
    "        return y\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a305a858-9fbd-432b-a302-517ad962ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniLLM(vocab_size, n_embed, head_size, n_head, block_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d2a09-2fbf-4294-a7cb-fe536ca525d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f0b877e-340d-4a38-b86f-73f4a3667dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3457, grad_fn=<DivBackward0>) 0\n",
      "tensor(3.3613, grad_fn=<DivBackward0>) 50\n",
      "tensor(3.3707, grad_fn=<DivBackward0>) 100\n",
      "tensor(3.3738, grad_fn=<DivBackward0>) 150\n",
      "tensor(3.4087, grad_fn=<DivBackward0>) 200\n",
      "tensor(3.3156, grad_fn=<DivBackward0>) 250\n",
      "tensor(3.3274, grad_fn=<DivBackward0>) 300\n",
      "tensor(3.2881, grad_fn=<DivBackward0>) 350\n",
      "tensor(3.3368, grad_fn=<DivBackward0>) 400\n",
      "tensor(3.3335, grad_fn=<DivBackward0>) 450\n",
      "tensor(3.2873, grad_fn=<DivBackward0>) 500\n",
      "tensor(3.1878, grad_fn=<DivBackward0>) 550\n",
      "tensor(3.3186, grad_fn=<DivBackward0>) 600\n",
      "tensor(3.2683, grad_fn=<DivBackward0>) 650\n",
      "tensor(3.2914, grad_fn=<DivBackward0>) 700\n",
      "tensor(3.2677, grad_fn=<DivBackward0>) 750\n",
      "tensor(3.3069, grad_fn=<DivBackward0>) 800\n",
      "tensor(3.2453, grad_fn=<DivBackward0>) 850\n",
      "tensor(3.2582, grad_fn=<DivBackward0>) 900\n",
      "tensor(3.2367, grad_fn=<DivBackward0>) 950\n",
      "tensor(3.2502, grad_fn=<DivBackward0>) 1000\n",
      "tensor(3.2176, grad_fn=<DivBackward0>) 1050\n",
      "tensor(3.2319, grad_fn=<DivBackward0>) 1100\n",
      "tensor(3.2246, grad_fn=<DivBackward0>) 1150\n",
      "tensor(3.2427, grad_fn=<DivBackward0>) 1200\n",
      "tensor(3.1534, grad_fn=<DivBackward0>) 1250\n",
      "tensor(3.1849, grad_fn=<DivBackward0>) 1300\n",
      "tensor(3.1999, grad_fn=<DivBackward0>) 1350\n",
      "tensor(3.2034, grad_fn=<DivBackward0>) 1400\n",
      "tensor(3.1759, grad_fn=<DivBackward0>) 1450\n",
      "tensor(3.1990, grad_fn=<DivBackward0>) 1500\n",
      "tensor(3.2010, grad_fn=<DivBackward0>) 1550\n",
      "tensor(3.1551, grad_fn=<DivBackward0>) 1600\n",
      "tensor(3.2204, grad_fn=<DivBackward0>) 1650\n",
      "tensor(3.1361, grad_fn=<DivBackward0>) 1700\n",
      "tensor(3.1956, grad_fn=<DivBackward0>) 1750\n",
      "tensor(3.1025, grad_fn=<DivBackward0>) 1800\n",
      "tensor(3.1310, grad_fn=<DivBackward0>) 1850\n",
      "tensor(3.1907, grad_fn=<DivBackward0>) 1900\n",
      "tensor(3.1598, grad_fn=<DivBackward0>) 1950\n",
      "tensor(3.1306, grad_fn=<DivBackward0>) 2000\n",
      "tensor(3.1583, grad_fn=<DivBackward0>) 2050\n",
      "tensor(3.1368, grad_fn=<DivBackward0>) 2100\n",
      "tensor(3.1261, grad_fn=<DivBackward0>) 2150\n",
      "tensor(3.1141, grad_fn=<DivBackward0>) 2200\n",
      "tensor(3.1294, grad_fn=<DivBackward0>) 2250\n",
      "tensor(3.0808, grad_fn=<DivBackward0>) 2300\n",
      "tensor(3.1074, grad_fn=<DivBackward0>) 2350\n",
      "tensor(3.1153, grad_fn=<DivBackward0>) 2400\n",
      "tensor(3.1450, grad_fn=<DivBackward0>) 2450\n",
      "tensor(3.1136, grad_fn=<DivBackward0>) 2500\n",
      "tensor(3.0955, grad_fn=<DivBackward0>) 2550\n",
      "tensor(3.0942, grad_fn=<DivBackward0>) 2600\n",
      "tensor(3.0838, grad_fn=<DivBackward0>) 2650\n",
      "tensor(3.1198, grad_fn=<DivBackward0>) 2700\n",
      "tensor(3.1222, grad_fn=<DivBackward0>) 2750\n",
      "tensor(3.1157, grad_fn=<DivBackward0>) 2800\n",
      "tensor(3.0691, grad_fn=<DivBackward0>) 2850\n",
      "tensor(3.0648, grad_fn=<DivBackward0>) 2900\n",
      "tensor(3.0772, grad_fn=<DivBackward0>) 2950\n",
      "tensor(3.0471, grad_fn=<DivBackward0>) 3000\n",
      "tensor(3.0676, grad_fn=<DivBackward0>) 3050\n",
      "tensor(3.0496, grad_fn=<DivBackward0>) 3100\n",
      "tensor(3.0505, grad_fn=<DivBackward0>) 3150\n",
      "tensor(3.0637, grad_fn=<DivBackward0>) 3200\n",
      "tensor(3.0569, grad_fn=<DivBackward0>) 3250\n",
      "tensor(3.0442, grad_fn=<DivBackward0>) 3300\n",
      "tensor(3.0700, grad_fn=<DivBackward0>) 3350\n",
      "tensor(3.0007, grad_fn=<DivBackward0>) 3400\n",
      "tensor(3.0116, grad_fn=<DivBackward0>) 3450\n",
      "tensor(3.0301, grad_fn=<DivBackward0>) 3500\n",
      "tensor(3.0653, grad_fn=<DivBackward0>) 3550\n",
      "tensor(3.0483, grad_fn=<DivBackward0>) 3600\n",
      "tensor(2.9913, grad_fn=<DivBackward0>) 3650\n",
      "tensor(2.9878, grad_fn=<DivBackward0>) 3700\n",
      "tensor(3.0491, grad_fn=<DivBackward0>) 3750\n",
      "tensor(3.0337, grad_fn=<DivBackward0>) 3800\n",
      "tensor(2.9272, grad_fn=<DivBackward0>) 3850\n",
      "tensor(2.9732, grad_fn=<DivBackward0>) 3900\n",
      "tensor(2.9847, grad_fn=<DivBackward0>) 3950\n",
      "tensor(2.9742, grad_fn=<DivBackward0>) 4000\n",
      "tensor(2.9973, grad_fn=<DivBackward0>) 4050\n",
      "tensor(2.9514, grad_fn=<DivBackward0>) 4100\n",
      "tensor(3.0198, grad_fn=<DivBackward0>) 4150\n",
      "tensor(2.9820, grad_fn=<DivBackward0>) 4200\n",
      "tensor(2.9455, grad_fn=<DivBackward0>) 4250\n",
      "tensor(2.9591, grad_fn=<DivBackward0>) 4300\n",
      "tensor(3.0085, grad_fn=<DivBackward0>) 4350\n",
      "tensor(2.9364, grad_fn=<DivBackward0>) 4400\n",
      "tensor(3.0130, grad_fn=<DivBackward0>) 4450\n",
      "tensor(2.9615, grad_fn=<DivBackward0>) 4500\n",
      "tensor(3.0133, grad_fn=<DivBackward0>) 4550\n",
      "tensor(2.9560, grad_fn=<DivBackward0>) 4600\n",
      "tensor(2.9996, grad_fn=<DivBackward0>) 4650\n",
      "tensor(2.9797, grad_fn=<DivBackward0>) 4700\n",
      "tensor(2.9494, grad_fn=<DivBackward0>) 4750\n",
      "tensor(2.9714, grad_fn=<DivBackward0>) 4800\n",
      "tensor(2.9728, grad_fn=<DivBackward0>) 4850\n",
      "tensor(2.9210, grad_fn=<DivBackward0>) 4900\n",
      "tensor(2.9063, grad_fn=<DivBackward0>) 4950\n",
      "tensor(2.9274, grad_fn=<DivBackward0>) 5000\n",
      "tensor(2.9988, grad_fn=<DivBackward0>) 5050\n",
      "tensor(2.9471, grad_fn=<DivBackward0>) 5100\n",
      "tensor(2.9272, grad_fn=<DivBackward0>) 5150\n",
      "tensor(2.9272, grad_fn=<DivBackward0>) 5200\n",
      "tensor(2.9137, grad_fn=<DivBackward0>) 5250\n",
      "tensor(2.8647, grad_fn=<DivBackward0>) 5300\n",
      "tensor(2.9202, grad_fn=<DivBackward0>) 5350\n",
      "tensor(2.8970, grad_fn=<DivBackward0>) 5400\n",
      "tensor(2.9027, grad_fn=<DivBackward0>) 5450\n",
      "tensor(2.8977, grad_fn=<DivBackward0>) 5500\n",
      "tensor(2.8908, grad_fn=<DivBackward0>) 5550\n",
      "tensor(2.8873, grad_fn=<DivBackward0>) 5600\n",
      "tensor(2.8430, grad_fn=<DivBackward0>) 5650\n",
      "tensor(2.8738, grad_fn=<DivBackward0>) 5700\n",
      "tensor(2.8816, grad_fn=<DivBackward0>) 5750\n",
      "tensor(2.8995, grad_fn=<DivBackward0>) 5800\n",
      "tensor(2.8762, grad_fn=<DivBackward0>) 5850\n",
      "tensor(2.8723, grad_fn=<DivBackward0>) 5900\n",
      "tensor(2.8238, grad_fn=<DivBackward0>) 5950\n",
      "tensor(2.8645, grad_fn=<DivBackward0>) 6000\n",
      "tensor(2.8508, grad_fn=<DivBackward0>) 6050\n",
      "tensor(2.8548, grad_fn=<DivBackward0>) 6100\n",
      "tensor(2.8869, grad_fn=<DivBackward0>) 6150\n",
      "tensor(2.8930, grad_fn=<DivBackward0>) 6200\n",
      "tensor(2.8942, grad_fn=<DivBackward0>) 6250\n",
      "tensor(2.8541, grad_fn=<DivBackward0>) 6300\n",
      "tensor(2.9152, grad_fn=<DivBackward0>) 6350\n",
      "tensor(2.8300, grad_fn=<DivBackward0>) 6400\n",
      "tensor(2.8736, grad_fn=<DivBackward0>) 6450\n",
      "tensor(2.8452, grad_fn=<DivBackward0>) 6500\n",
      "tensor(2.8828, grad_fn=<DivBackward0>) 6550\n",
      "tensor(2.8240, grad_fn=<DivBackward0>) 6600\n",
      "tensor(2.8572, grad_fn=<DivBackward0>) 6650\n",
      "tensor(2.8678, grad_fn=<DivBackward0>) 6700\n",
      "tensor(2.8830, grad_fn=<DivBackward0>) 6750\n",
      "tensor(2.8476, grad_fn=<DivBackward0>) 6800\n",
      "tensor(2.8174, grad_fn=<DivBackward0>) 6850\n",
      "tensor(2.7832, grad_fn=<DivBackward0>) 6900\n",
      "tensor(2.8229, grad_fn=<DivBackward0>) 6950\n",
      "tensor(2.8347, grad_fn=<DivBackward0>) 7000\n",
      "tensor(2.8078, grad_fn=<DivBackward0>) 7050\n",
      "tensor(2.7867, grad_fn=<DivBackward0>) 7100\n",
      "tensor(2.8509, grad_fn=<DivBackward0>) 7150\n",
      "tensor(2.7718, grad_fn=<DivBackward0>) 7200\n",
      "tensor(2.8106, grad_fn=<DivBackward0>) 7250\n",
      "tensor(2.7815, grad_fn=<DivBackward0>) 7300\n",
      "tensor(2.7655, grad_fn=<DivBackward0>) 7350\n",
      "tensor(2.7877, grad_fn=<DivBackward0>) 7400\n",
      "tensor(2.7776, grad_fn=<DivBackward0>) 7450\n",
      "tensor(2.7998, grad_fn=<DivBackward0>) 7500\n",
      "tensor(2.7606, grad_fn=<DivBackward0>) 7550\n",
      "tensor(2.7528, grad_fn=<DivBackward0>) 7600\n",
      "tensor(2.7861, grad_fn=<DivBackward0>) 7650\n",
      "tensor(2.7722, grad_fn=<DivBackward0>) 7700\n",
      "tensor(2.7419, grad_fn=<DivBackward0>) 7750\n",
      "tensor(2.7874, grad_fn=<DivBackward0>) 7800\n",
      "tensor(2.8220, grad_fn=<DivBackward0>) 7850\n",
      "tensor(2.7781, grad_fn=<DivBackward0>) 7900\n",
      "tensor(2.7985, grad_fn=<DivBackward0>) 7950\n",
      "tensor(2.7578, grad_fn=<DivBackward0>) 8000\n",
      "tensor(2.7557, grad_fn=<DivBackward0>) 8050\n",
      "tensor(2.7229, grad_fn=<DivBackward0>) 8100\n",
      "tensor(2.7337, grad_fn=<DivBackward0>) 8150\n",
      "tensor(2.7604, grad_fn=<DivBackward0>) 8200\n",
      "tensor(2.7552, grad_fn=<DivBackward0>) 8250\n",
      "tensor(2.6956, grad_fn=<DivBackward0>) 8300\n",
      "tensor(2.7647, grad_fn=<DivBackward0>) 8350\n",
      "tensor(2.7461, grad_fn=<DivBackward0>) 8400\n",
      "tensor(2.7882, grad_fn=<DivBackward0>) 8450\n",
      "tensor(2.7455, grad_fn=<DivBackward0>) 8500\n",
      "tensor(2.7523, grad_fn=<DivBackward0>) 8550\n",
      "tensor(2.7401, grad_fn=<DivBackward0>) 8600\n",
      "tensor(2.7113, grad_fn=<DivBackward0>) 8650\n",
      "tensor(2.7384, grad_fn=<DivBackward0>) 8700\n",
      "tensor(2.7471, grad_fn=<DivBackward0>) 8750\n",
      "tensor(2.7395, grad_fn=<DivBackward0>) 8800\n",
      "tensor(2.7505, grad_fn=<DivBackward0>) 8850\n",
      "tensor(2.7172, grad_fn=<DivBackward0>) 8900\n",
      "tensor(2.7966, grad_fn=<DivBackward0>) 8950\n",
      "tensor(2.7881, grad_fn=<DivBackward0>) 9000\n",
      "tensor(2.6700, grad_fn=<DivBackward0>) 9050\n",
      "tensor(2.7535, grad_fn=<DivBackward0>) 9100\n",
      "tensor(2.7255, grad_fn=<DivBackward0>) 9150\n",
      "tensor(2.6609, grad_fn=<DivBackward0>) 9200\n",
      "tensor(2.7349, grad_fn=<DivBackward0>) 9250\n",
      "tensor(2.6912, grad_fn=<DivBackward0>) 9300\n",
      "tensor(2.7227, grad_fn=<DivBackward0>) 9350\n",
      "tensor(2.7266, grad_fn=<DivBackward0>) 9400\n",
      "tensor(2.6725, grad_fn=<DivBackward0>) 9450\n",
      "tensor(2.7281, grad_fn=<DivBackward0>) 9500\n",
      "tensor(2.6590, grad_fn=<DivBackward0>) 9550\n",
      "tensor(2.6958, grad_fn=<DivBackward0>) 9600\n",
      "tensor(2.6747, grad_fn=<DivBackward0>) 9650\n",
      "tensor(2.6529, grad_fn=<DivBackward0>) 9700\n",
      "tensor(2.6819, grad_fn=<DivBackward0>) 9750\n",
      "tensor(2.6901, grad_fn=<DivBackward0>) 9800\n",
      "tensor(2.6543, grad_fn=<DivBackward0>) 9850\n",
      "tensor(2.6899, grad_fn=<DivBackward0>) 9900\n",
      "tensor(2.7076, grad_fn=<DivBackward0>) 9950\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_epochs = 10000\n",
    "\n",
    "ar = torch.arange(block_size)\n",
    "br = torch.arange(1, block_size+1)\n",
    "losses = []\n",
    "for _ in range(num_epochs): \n",
    "    idx = torch.randint(len(train_data) - block_size - 1, (batch_size, 1))\n",
    "    x = train_data[idx+ar]\n",
    "    y = train_data[idx+br]\n",
    "    logits, loss = model(x, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss)\n",
    "    if _%50==0: \n",
    "        print(sum(losses)/len(losses), _)\n",
    "        losses = []\n",
    "b, t = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abee01cc-42af-4bbe-b2ad-1806f4c09ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.generate(x, num_new_token=500, context_limit=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "271e9b9e-81d0-406b-a452-253a7499c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.decode(y[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58442d59-fa8a-42c5-8d7e-054977d065ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\":\\nMarry, my child, and and my brother,\\nThoughts for my poor lord, this this is the world goes,\\nThe Clifford Clifford's rigour of the statute,\\nTo make him the precedent and witness witness\\nThe words that he hath hath fallen by prompt prompt me to the blood of your blood,\\nCurrents from thence thence,\\n\\nSICINIUS:\\nThe gods, for your voices!\\n\\nMENENIUS:\\nThe gods have neither neither, my lord,\\nBut repetition will what what thou go?\\n\\nMERCUTIO:\\nNay, but he's dead; and he he knows not not,\\nThe ape is dead, but that's my lord.\\n\\nKING RICHARD III:\\nThe advancement of your children children, go we\\nInjurious Margaret!\\n\\nMERCUTIO:\\nNay, but he's dead; and he he knows not not,\\nThe ape is dead, but that's my lord.\\n\\nKING RICHARD III:\\nThe advancement of your children children, go we\\nInjurious Margaret!\\n\\nMERCUTIO:\\nNay, but he's dead; and he he knows not not,\\nThe ape is dead, but that's my lord.\\n\\nKING RICHARD III:\\nThe advancement of your children children, go we\\nInjurious Margaret!\\n\\nMERCUTIO:\\nNay, but he's dead; and he he knows not not,\\nThe ape is dead, but that's my lord.\\n\\nKING RICHARD III:\\nThe advancement of your children children, go we\\nInjurious Margaret!\\n\\nMERCUTIO:\\nNay, but he's dead; and he he knows not not,\\nThe ape is dead, but that's my lord.\\n\\nKING RICHARD III:\\nThe advancement of your children children, go we\\nInjurious Margaret!\\n\\nMERCUTIO:\\nNay, but he's dead; and he he knows not not,\\nThe ape is dead, but that's my lord.\\n\\nKING RICHARD III:\\nThe advancement of your children children, go we\\nInjurious Margaret!\\n\\nMERCUTIO:\\nNay, but he's dead; and he he knows not not,\\nThe ape is dead, but that's my lord.\\n\\nKING\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae1ebcf-6b5d-47a6-81fc-59bf2b51c754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e9580-e6b7-46be-abb6-d61add54594b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7b04b-4bfb-4d7f-9e58-aa833ebeeb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
